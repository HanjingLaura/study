# SFT
## 需求与技术
- 需求
    - 提高对专有知识的理解，增强在特定行业领域的知识——SFT
    - 提供个性化和互动性强的服务—RLHF
    - 提高模型对专有信息的理解，获取和生成最新的实时的信息——RAG
- SFT,RLHF,RAG
    - SFT(Supervised Fine-Tuning)有监督微调
        - 通过人工标注的数据，进一步训练预训练模型，让模型能够更加精准的处理特定领域的任务
        - 除了有监督微调还有无监督微调，自监督微调，微调通常指有监督微调
    - RLHF(Reinforcement Learning from Human Feedback)强化学习
        - DPO(Direct Preference Optimization)
            - 核心：通过人类对比选择，直接优化模型，产生更符合用户需求的结果，调整幅度大
        - PPO( Proximal Policy Optimization)
            - 核心：通过奖励信号来渐进式调整模型的行为策略，调整幅度小
    - RAG(Retrieval-Argument Generation)检索增强生成
        - 将外部信息检索与文本生成结合，帮助模型在生成答案时，实时获取外部信息的最新信息
- 微调 or RAG
    - 微调
        - 适合：有非常充足的资源
        - 能够直接提升模型的固有能力
    - RAG
        -  适合：只有非常少的资源，动态更新的数据
        -  每次回答问题前序耗时检索知识库，回答质量依赖于检索系统的质量
    - 总结
        - 少量私有知识：微调+RAG
        - 动态更新的知识：RAG
        - 大量垂直领域知识：微调
- SFT(有监督微调)
    - 通过人工标注的数据，进一步训练预训练模型，让模型能够更加精准的处理特定领域的任务
    - 人工标注的数据
        - eg：
            - 分类系统
            ```
            {"image_path":"path/image1.jpg","label":"eg1"}
            {"image_path":"path/image2.jpg","label":"eg2"}
            ```
            - 对话系统
            ```
            {
                "instruction":"请问你是谁"，
                "input":"",
                "output":"您好我是微调后的大模型"，
            }
            ```
    - 预训练模型
        - 指已经在大量数据上训练过的模型，也就是我们预先要下载的开源模型，它具备了较为通用的知识和能力，能够解决一些常见的任务，可在此基础上进一步微调(fine-tuning)，以适应特定是任务领域
    - 微调算法的分类
        - 全参数微调(Full Fine-tuning)
            - 对整个预训练模型进行微调，会更新所有参数
            - 优点：每个参数都可以调整，通常能达到最佳的性能，能够适应不同的任务和场景
            - 缺点：需要较大计算资源且容易出现过拟合
        - 部分参数微调(Partial Fine-Tuning)
            - 只更新模型的部分参数
            - 优点：减少了计算成本，减少过拟合缺点，能够以较小的代价获得较好的结果
            - 缺点：可能无法达到最佳性能
            - 最著名算法：LoRA
- LoRA微调算法
    - 矩阵的秩
        - 矩阵中线性无关的行或列的最大数量，简单来说可以反应矩阵所包含的有效信息量
    - LoRA
        - h = W0x + delta Wx = W0x + BAx
            - h：模型输出
            - W0：预训练模型的原始权重，是一个全秩矩阵
            - x：模型输入
            - delta Wx：微调后原始权重的变化量，也是一个全秩矩阵，大小和W0相同
            - BA：两个低秩矩阵B和A，乘积BA表示对原始权重的变化量
            - W0x + delta Wx ——全参数微调的输出
            - W0x + BAx ——用LoRA方法对部分参数微调的输出
        - LoRA训练后通常需要进行权重合并
- 微调常见实现框架
    - Llama-Factory
    - transformers.Trainer
    - DeepSpeed